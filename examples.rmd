---
title: "Parallel computing in R. A brief introduction and a few examples"
author:
    - names: "Sergio Picó Jordá"
    - affiliations: INMAR, Departamento de Biología, Universidad de Cádiz.
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        code_folding: false
        toc: true
        toc_depth: 3
        css: styles.css
editor_options:
    chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```


# Parallel computing in R. A brief introduction and a few examples.



## What is parallel computing?
Parallel computation is the simultaneous executions of different pieces of a
(normally large) computation across multiple processors or cores. The interest of
this technique is that you can execute a process that takes *x* seconds on a
single processor in *x/n* seconds using *n* processors (this is the ideal case,
that is rarely possible to achieve).

We can use this in a supercomputer (like the [UCA's
cluster](https://supercomputacion.uca.es/)), but also in almost any device with multiple processors or cores. And happily nowadays most of our PCs and laptops have multicore processors.

How serial computing sometimes looks like in our
computers, as it happens most of the time in R (awesome GIF from my WOT gaming years):

![CPU 0 doing all the heavy lifting](https://tenor.com/view/wot-cpu-danceing-break-dancing-cool-gif-16563810.gif)

Instead, we want our cores to be a team!:

![Teamwork!](https://media.giphy.com/media/qowPpT1lFY89MN2BVn/giphy.gif)



## How to do parallel computing in R

Ok, so how does this work? We need to create a structure that sets a *director node* that is going to distribute data and functions between the *workers*, that will execute the interactions. This structure will allocate and manage the resorces, like number of cores, RAM memory and so. I will show you two different systems: **FORK** and
**PSOCK**.

## Examples

### Making apply functions parallel

We can make the functions from the *apply* family parallel , [example by Jens Moll-Elsborg](https://towardsdatascience.com/getting-started-with-parallel-programming-in-r-d5f801d43745). Create the data:

```{create data}
# Create a vector with 1 billion elements
data <- 1:1e9

# Make a list of 4 of these vectors
data_list <- list("1" = data,
                  "2" = data,
                  "3" = data,
                  "4" = data
)
```
Calculate the mean 

```{serial mean}
# Calculate the mean of every vector
time_benchmark <- system.time(
    lapply(data_list, mean)
)
time_benchmark # Total of 12.83s in my machine
```
This is fine, but let's make our cores share the effort:

Linux/Mac version:

```{parallel mean linux/mac}
# Load package parallel
library(parallel)
detectCores()

parallel::mclapply(1:10, function(x) {
                   mean(data_list)
          },       mc.cores = 8)
```

Windows version:

```{parallel mean windows}
# Load package parallel
library(parallel)

# Detect number of cores, create a local cluster
parallel::detectCores()
cl <- parallel::makeCluster(8)

# Run the same process but in parallel
time_parallel  <- system.time(
    parallel::parLapply(cl,
                        data_list,
                        mean)
)

# Stop cluster
parallel::stopCluster(cl)
```

### Running a loop in parallel

We can also parallelise a for loop.

Linux/Mac version:

```{loop parallel Linux/Mac}
# Load packages
library(doParallel)
library(parallel)
library(foreach)

# Activate the cluster for foreach
doParallel::registerDoParallel(cores = 8)

# Calculate mean
time_foreach <- system.time({
     r <- foreach(i = 1:length(data_list),
                  .combine = rbind) %dopar% {
          mean(data_list[[i]])
     }
}
)

time_foreach[3]
```

Windows version:

```{loop parallel windows}
library(doParallel)
library(parallel)
library(foreach)

# Detect number of cores and create cluster
cl <- parallel::makeCluster(detectCores())

# Activate the cluster for foreach
doParallel::registerDoParallel(cl)

# Calculate mean
time_foreach <- system.time({
    r <- foreach(i = 1:length(data_list),
                 .combine = rbind) %dopar% {
         mean(data_list[[i]])
    }
}
)

time_foreach[3]

# Stop cluster
parallel::stopCluster(cl)
```


### A real example: Random forest with ranger

This is a great example showed by Blas Benito in [his blog](https://www.blasbenito.com/post/02_parallelizing_loops_with_r/).

```{load packages}
library(palmerpenguins)
library(ranger)
```

The goal of this process is to classify penguins from different species using measurements of bill length, bill depth, flipper length, and body mass. Prepare the data:

```{prepare data}
penguins <- as.data.frame(
    na.omit(
        penguins[, c("species",
                     "bill_length_mm",
                     "bill_depth_mm",
                     "flipper_length_mm",
                     "body_mass_g"
        )]
    )
)
```

Now, fit a random forest model using the *ranger* package:

```{fit rf}

# Fit model
m <- ranger::ranger(
    data = penguins,
    dependent.variable.name = "species",
    importance = "permutation"
)

# Check results
m
m$variable.importance

```

Now, let's do a grid search for hyperparameter optimization. We are going to fit many models with diferent hyperparameter combinations to find the combination with the best prediction error. Hyperparameters: number of trees (num.trees), number of variables selected by chance for a tree split (mtry), mminimum number of cases in a terminal node (min.node.size).

```{optimization}

# Create a table with all combinations
sensitivity.df  <- expand.grid(
    num.trees = c(500, 1000, 1500),
    mtry = 2:4,
    min.node.size = c(1, 10, 20)
)

# 27 combinations of hyperparameters

# Create and register cluster
cl <- parallel:makeCluster(8)
doParallel::registerDoParallel(cl)

# Fit models
prediction.error <- foreach(
# Iterate over the hyperparameter data frame
    num.trees = sensitivity.df$num.trees,
    mtry = sensitivity.df$mtry,
    min.node.size = sensitivity.df$min.node.size,
    .combine = "c",
    . packages = "ranger"
) %dopar% {

    # Fit model
    m.i <- ranger::ranger(
        data = penguins,
        dependent.variable.name = "species",
        num.trees = num.trees,
        mtry = mtry,
        min.node.size = min.node.size
    )
return(m.i$prediction.error * 100)
}

# 
```

